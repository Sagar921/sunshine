{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd # for data manupulation or analysis\n",
    "import numpy as np # for numeric calculation\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import seaborn as sns # for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  diluted wines  Proline      \n",
       "0             5.64  1.04           3.92         1065  \n",
       "1             4.38  1.05           3.40         1050  \n",
       "2             5.68  1.03           3.17         1185  \n",
       "3             7.80  0.86           3.45         1480  \n",
       "4             4.32  1.04           2.93          735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:\\\\DATA-TRAINED\\\\dataset1-master\\\\dataset1-master\\\\winedataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (142, 13)\n",
      "shape of x_test: (36, 13)\n",
      "shape of y_train: (142,)\n",
      "shape of y_test: (36,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of x_train:',x_train.shape)\n",
    "print('shape of x_test:',x_test.shape)\n",
    "print('shape of y_train:',y_train.shape)\n",
    "print('shape of y_test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>12.72</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.8</td>\n",
       "      <td>86</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.16</td>\n",
       "      <td>3.14</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>13.29</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.68</td>\n",
       "      <td>16.8</td>\n",
       "      <td>102</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.66</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>13.05</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2.13</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.10</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>12.81</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.40</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.36</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13.76</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>19.5</td>\n",
       "      <td>132</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.61</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.70</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.26</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>12.84</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.61</td>\n",
       "      <td>24.0</td>\n",
       "      <td>101</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.15</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "81     12.72        1.81  2.20               18.8         86           2.20   \n",
       "160    12.36        3.83  2.38               21.0         88           2.30   \n",
       "16     14.30        1.92  2.72               20.0        120           2.80   \n",
       "57     13.29        1.97  2.68               16.8        102           3.00   \n",
       "123    13.05        5.80  2.13               21.5         86           2.62   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "132    12.81        2.31  2.40               24.0         98           1.15   \n",
       "33     13.76        1.53  2.70               19.5        132           2.95   \n",
       "109    11.61        1.35  2.70               20.0         94           2.74   \n",
       "139    12.84        2.96  2.61               24.0        101           2.32   \n",
       "176    13.17        2.59  2.37               20.0        120           1.65   \n",
       "\n",
       "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "81         2.53                  0.26             1.77             3.90  1.16   \n",
       "160        0.92                  0.50             1.04             7.65  0.56   \n",
       "16         3.14                  0.33             1.97             6.20  1.07   \n",
       "57         3.23                  0.31             1.66             6.00  1.07   \n",
       "123        2.65                  0.30             2.01             2.60  0.73   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "132        1.09                  0.27             0.83             5.70  0.66   \n",
       "33         2.74                  0.50             1.35             5.40  1.25   \n",
       "109        2.92                  0.29             2.49             2.65  0.96   \n",
       "139        0.60                  0.53             0.81             4.92  0.89   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "\n",
       "     diluted wines  Proline      \n",
       "81            3.14          714  \n",
       "160           1.58          520  \n",
       "16            2.65         1280  \n",
       "57            2.84         1270  \n",
       "123           3.10          380  \n",
       "..             ...          ...  \n",
       "132           1.36          560  \n",
       "33            3.00         1235  \n",
       "109           3.26          680  \n",
       "139           2.15          590  \n",
       "176           1.62          840  \n",
       "\n",
       "[142 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>12.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>22.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.96</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.5</td>\n",
       "      <td>81</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.27</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>12.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.12</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>13.36</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>89</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.47</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>13.62</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.05</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>12.60</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.5</td>\n",
       "      <td>94</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.58</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12.42</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.73</td>\n",
       "      <td>26.5</td>\n",
       "      <td>102</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.12</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>12.77</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.12</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12.82</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>88</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13.56</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.31</td>\n",
       "      <td>16.2</td>\n",
       "      <td>117</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.34</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.38</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>12.00</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.05</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>12.37</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>87</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.87</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>13.88</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.33</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.50</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.19</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>12.08</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.70</td>\n",
       "      <td>17.5</td>\n",
       "      <td>97</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.96</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>13.74</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>16.4</td>\n",
       "      <td>118</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.62</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>95</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12.43</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.84</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13.07</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>15.5</td>\n",
       "      <td>98</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>98</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.54</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>126</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.65</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.71</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>11.82</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.88</td>\n",
       "      <td>19.5</td>\n",
       "      <td>86</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.44</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>12.99</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.60</td>\n",
       "      <td>30.0</td>\n",
       "      <td>139</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.96</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.31</td>\n",
       "      <td>3.50</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.22</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.51</td>\n",
       "      <td>13.2</td>\n",
       "      <td>128</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.53</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>11.79</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.78</td>\n",
       "      <td>28.5</td>\n",
       "      <td>92</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.44</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>14.10</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.40</td>\n",
       "      <td>18.8</td>\n",
       "      <td>103</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.38</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>105</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>13.17</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12.07</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>85</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.28</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "117    12.42        1.61  2.19               22.5        108           2.00   \n",
       "90     12.08        1.83  2.32               18.5         81           1.60   \n",
       "80     12.00        0.92  2.00               19.0         86           2.42   \n",
       "141    13.36        2.56  2.35               20.0         89           1.40   \n",
       "143    13.62        4.95  2.35               20.0         92           2.00   \n",
       "135    12.60        2.46  2.20               18.5         94           1.62   \n",
       "122    12.42        4.43  2.73               26.5        102           2.20   \n",
       "118    12.77        3.43  1.98               16.0         80           1.63   \n",
       "24     13.50        1.81  2.61               20.0         96           2.53   \n",
       "167    12.82        3.37  2.30               19.5         88           1.48   \n",
       "40     13.56        1.71  2.31               16.2        117           3.15   \n",
       "25     13.05        2.05  3.22               25.0        124           2.63   \n",
       "119    12.00        3.43  2.00               19.0         87           2.00   \n",
       "12     13.75        1.73  2.41               16.0         89           2.60   \n",
       "63     12.37        1.13  2.16               19.0         87           3.50   \n",
       "146    13.88        5.04  2.23               20.0         80           0.98   \n",
       "114    12.08        1.39  2.50               22.5         84           2.56   \n",
       "159    13.48        1.67  2.64               22.5         89           2.60   \n",
       "100    12.08        2.08  1.70               17.5         97           2.23   \n",
       "54     13.74        1.67  2.25               16.4        118           2.60   \n",
       "23     12.85        1.60  2.52               17.8         95           2.48   \n",
       "126    12.43        1.53  2.29               21.5         86           2.74   \n",
       "38     13.07        1.50  2.10               15.5         98           2.40   \n",
       "153    13.23        3.30  2.28               18.5         98           1.80   \n",
       "34     13.51        1.80  2.65               19.0        110           2.35   \n",
       "20     14.06        1.63  2.28               16.0        126           3.00   \n",
       "103    11.82        1.72  1.88               19.5         86           2.50   \n",
       "73     12.99        1.67  2.60               30.0        139           3.30   \n",
       "39     14.22        3.99  2.51               13.2        128           3.00   \n",
       "127    11.79        2.13  2.78               28.5         92           2.13   \n",
       "48     14.10        2.02  2.40               18.8        103           2.75   \n",
       "8      14.83        1.64  2.17               14.0         97           2.80   \n",
       "168    13.58        2.58  2.69               24.5        105           1.55   \n",
       "155    13.17        5.19  2.32               22.0         93           1.74   \n",
       "13     14.75        1.73  2.39               11.4         91           3.10   \n",
       "125    12.07        2.16  2.17               21.0         85           2.60   \n",
       "\n",
       "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "117        2.09                  0.34             1.61             2.06  1.06   \n",
       "90         1.50                  0.52             1.64             2.40  1.08   \n",
       "80         2.26                  0.30             1.43             2.50  1.38   \n",
       "141        0.50                  0.37             0.64             5.60  0.70   \n",
       "143        0.80                  0.47             1.02             4.40  0.91   \n",
       "135        0.66                  0.63             0.94             7.10  0.73   \n",
       "122        2.13                  0.43             1.71             2.08  0.92   \n",
       "118        1.25                  0.43             0.83             3.40  0.70   \n",
       "24         2.61                  0.28             1.66             3.52  1.12   \n",
       "167        0.66                  0.40             0.97            10.26  0.72   \n",
       "40         3.29                  0.34             2.34             6.13  0.95   \n",
       "25         2.68                  0.47             1.92             3.58  1.13   \n",
       "119        1.64                  0.37             1.87             1.28  0.93   \n",
       "12         2.76                  0.29             1.81             5.60  1.15   \n",
       "63         3.10                  0.19             1.87             4.45  1.22   \n",
       "146        0.34                  0.40             0.68             4.90  0.58   \n",
       "114        2.29                  0.43             1.04             2.90  0.93   \n",
       "159        1.10                  0.52             2.29            11.75  0.57   \n",
       "100        2.17                  0.26             1.40             3.30  1.27   \n",
       "54         2.90                  0.21             1.62             5.85  0.92   \n",
       "23         2.37                  0.26             1.46             3.93  1.09   \n",
       "126        3.15                  0.39             1.77             3.94  0.69   \n",
       "38         2.64                  0.28             1.37             3.70  1.18   \n",
       "153        0.83                  0.61             1.87            10.52  0.56   \n",
       "34         2.53                  0.29             1.54             4.20  1.10   \n",
       "20         3.17                  0.24             2.10             5.65  1.09   \n",
       "103        1.64                  0.37             1.42             2.06  0.94   \n",
       "73         2.89                  0.21             1.96             3.35  1.31   \n",
       "39         3.04                  0.20             2.08             5.10  0.89   \n",
       "127        2.24                  0.58             1.76             3.00  0.97   \n",
       "48         2.92                  0.32             2.38             6.20  1.07   \n",
       "8          2.98                  0.29             1.98             5.20  1.08   \n",
       "168        0.84                  0.39             1.54             8.66  0.74   \n",
       "155        0.63                  0.61             1.55             7.90  0.60   \n",
       "13         3.69                  0.43             2.81             5.40  1.25   \n",
       "125        2.65                  0.37             1.35             2.76  0.86   \n",
       "\n",
       "     diluted wines  Proline      \n",
       "117           2.96          345  \n",
       "90            2.27          480  \n",
       "80            3.12          278  \n",
       "141           2.47          780  \n",
       "143           2.05          550  \n",
       "135           1.58          695  \n",
       "122           3.12          365  \n",
       "118           2.12          372  \n",
       "24            3.82          845  \n",
       "167           1.75          685  \n",
       "40            3.38          795  \n",
       "25            3.20          830  \n",
       "119           3.05          564  \n",
       "12            2.90         1320  \n",
       "63            2.87          420  \n",
       "146           1.33          415  \n",
       "114           3.19          385  \n",
       "159           1.78          620  \n",
       "100           2.96          710  \n",
       "54            3.20         1060  \n",
       "23            3.63         1015  \n",
       "126           2.84          352  \n",
       "38            2.69         1020  \n",
       "153           1.51          675  \n",
       "34            2.87         1095  \n",
       "20            3.71          780  \n",
       "103           2.44          415  \n",
       "73            3.50          985  \n",
       "39            3.53          760  \n",
       "127           2.44          466  \n",
       "48            2.75         1060  \n",
       "8             2.85         1045  \n",
       "168           1.80          750  \n",
       "155           1.48          725  \n",
       "13            2.73         1150  \n",
       "125           3.28          378  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81     2\n",
       "160    3\n",
       "16     1\n",
       "57     1\n",
       "123    2\n",
       "      ..\n",
       "132    3\n",
       "33     1\n",
       "109    2\n",
       "139    3\n",
       "176    3\n",
       "Name: Class, Length: 142, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117    2\n",
       "90     2\n",
       "80     2\n",
       "141    3\n",
       "143    3\n",
       "135    3\n",
       "122    2\n",
       "118    2\n",
       "24     1\n",
       "167    3\n",
       "40     1\n",
       "25     1\n",
       "119    2\n",
       "12     1\n",
       "63     2\n",
       "146    3\n",
       "114    2\n",
       "159    3\n",
       "100    2\n",
       "54     1\n",
       "23     1\n",
       "126    2\n",
       "38     1\n",
       "153    3\n",
       "34     1\n",
       "20     1\n",
       "103    2\n",
       "73     2\n",
       "39     1\n",
       "127    2\n",
       "48     1\n",
       "8      1\n",
       "168    3\n",
       "155    3\n",
       "13     1\n",
       "125    2\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DecisionTreeClassifier() is:\n",
      "0.9444444444444444\n",
      "[[11  2  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.88      1.00      0.93        14\n",
      "           3       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.95      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score of SVC() is:\n",
      "0.6111111111111112\n",
      "[[ 9  4  0]\n",
      " [ 1 13  0]\n",
      " [ 0  9  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.69      0.78        13\n",
      "           2       0.50      0.93      0.65        14\n",
      "           3       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.47      0.54      0.48        36\n",
      "weighted avg       0.52      0.61      0.54        36\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score of KNeighborsClassifier() is:\n",
      "0.6666666666666666\n",
      "[[10  0  3]\n",
      " [ 1 12  1]\n",
      " [ 1  6  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.77      0.80        13\n",
      "           2       0.67      0.86      0.75        14\n",
      "           3       0.33      0.22      0.27         9\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.61      0.62      0.61        36\n",
      "weighted avg       0.64      0.67      0.65        36\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score of MultinomialNB() is:\n",
      "0.8611111111111112\n",
      "[[ 9  4  0]\n",
      " [ 0 14  0]\n",
      " [ 1  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.69      0.78        13\n",
      "           2       0.78      1.00      0.88        14\n",
      "           3       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.89      0.86      0.87        36\n",
      "weighted avg       0.88      0.86      0.86        36\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model=[DecisionTreeClassifier(),SVC(),KNeighborsClassifier(),MultinomialNB()]\n",
    "\n",
    "\n",
    "for m in model:\n",
    "    m.fit(x_train,y_train)\n",
    "    m.score(x_train,y_train)\n",
    "    predm=m.predict(x_test)\n",
    "    print('Accuracy score of',m,'is:')\n",
    "    print(accuracy_score(y_test,predm))\n",
    "    print(confusion_matrix(y_test,predm))\n",
    "    print(classification_report(y_test,predm))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train_sc = sc.fit_transform(x_train)\n",
    "x_test_sc = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppor vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector classifier\n",
    "from sklearn.svm import SVC\n",
    "svc_classifier = SVC()\n",
    "svc_classifier.fit(x_train, y_train)\n",
    "y_predm_scv = svc_classifier.predict(x_test)\n",
    "accuracy_score(y_test, y_predm_scv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with Standard scaled Data\n",
    "svc_classifier2 = SVC()\n",
    "svc_classifier2.fit(x_train_sc, y_train)\n",
    "y_predm_svc_sc = svc_classifier2.predict(x_test_sc)\n",
    "accuracy_score(y_test, y_predm_svc_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_classifier = LogisticRegression(random_state = 51, penalty = 'l2')\n",
    "lr_classifier.fit(x_train, y_train)\n",
    "y_predm_lr = lr_classifier.predict(x_test)\n",
    "accuracy_score(y_test, y_predm_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with Standard scaled Data\n",
    "lr_classifier2 = LogisticRegression(random_state = 51, penalty = 'l2')\n",
    "lr_classifier2.fit(x_train_sc, y_train)\n",
    "y_pred_lr_sc = lr_classifier.predict(x_test_sc)\n",
    "accuracy_score(y_test, y_pred_lr_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K – Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "y_predm_knn = knn_classifier.predict(x_test)\n",
    "accuracy_score(y_test, y_predm_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3888888888888889"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with Standard scaled Data\n",
    "knn_classifier2 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "knn_classifier2.fit(x_train_sc, y_train)\n",
    "y_predm_knn_sc = knn_classifier.predict(x_test_sc)\n",
    "accuracy_score(y_test, y_predm_knn_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(x_train, y_train)\n",
    "y_predm_nb = nb_classifier.predict(x_test)\n",
    "accuracy_score(y_test, y_predm_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with Standard scaled Data\n",
    "nb_classifier2 = GaussianNB()\n",
    "nb_classifier2.fit(x_train_sc, y_train)\n",
    "y_predm_nb_sc = nb_classifier2.predict(x_test_sc)\n",
    "accuracy_score(y_test, y_predm_nb_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)\n",
    "dt_classifier.fit(x_train, y_train)\n",
    "y_predm_dt = dt_classifier.predict(x_test)\n",
    "accuracy_score(y_test, y_predm_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with Standard scaled Data\n",
    "dt_classifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)\n",
    "dt_classifier2.fit(x_train_sc, y_train)\n",
    "y_predm_dt_sc = dt_classifier.predict(x_test_sc)\n",
    "accuracy_score(y_test, y_predm_dt_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
